{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67895510",
   "metadata": {},
   "source": [
    "Write a Python script that:\n",
    "Use Genism to preprocess data from a sample text file, follow basic procedures like tokenization, stemming, lemmatization etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f45049f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\edbid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\edbid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: ['natural', 'language', 'processing', 'nlp', 'is', 'fascinating', 'domain', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', 'it', 'involves', 'breaking', 'down', 'text', 'into', 'smaller', 'components', 'such', 'as', 'words', 'or', 'sentences', 'through', 'tokenization', 'additionally', 'processes', 'like', 'stemming', 'and', 'lemmatization', 'help', 'reduce', 'words', 'to', 'their', 'base', 'forms', 'ensuring', 'consistency', 'in', 'analysis', 'applications', 'of', 'nlp', 'include', 'chatbots', 'sentiment', 'analysis', 'language', 'translation', 'and', 'more', 'the', 'ability', 'to', 'process', 'and', 'understand', 'natural', 'language', 'opens', 'up', 'world', 'of', 'possibilities', 'for', 'making', 'technology', 'smarter', 'and', 'more', 'accessible', 'to', 'users']\n",
      "Text after Removing Stopwords: ['natural', 'language', 'processing', 'nlp', 'fascinating', 'domain', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'human', 'language', 'involves', 'breaking', 'text', 'smaller', 'components', 'words', 'sentences', 'tokenization', 'additionally', 'processes', 'like', 'stemming', 'lemmatization', 'help', 'reduce', 'words', 'base', 'forms', 'ensuring', 'consistency', 'analysis', 'applications', 'nlp', 'include', 'chatbots', 'sentiment', 'analysis', 'language', 'translation', 'ability', 'process', 'understand', 'natural', 'language', 'opens', 'world', 'possibilities', 'making', 'technology', 'smarter', 'accessible', 'users']\n",
      "Text after Stemming: ['natur', 'languag', 'process', 'nlp', 'fascin', 'domain', 'artifici', 'intellig', 'focus', 'interact', 'comput', 'human', 'languag', 'involv', 'break', 'text', 'smaller', 'compon', 'word', 'sentenc', 'token', 'addition', 'process', 'like', 'stem', 'lemmat', 'help', 'reduc', 'word', 'base', 'form', 'ensur', 'consist', 'analysi', 'applic', 'nlp', 'includ', 'chatbot', 'sentiment', 'analysi', 'languag', 'translat', 'abil', 'process', 'understand', 'natur', 'languag', 'open', 'world', 'possibl', 'make', 'technolog', 'smarter', 'access', 'user']\n",
      "Text after Lemmatization: ['natural', 'language', 'processing', 'nlp', 'fascinating', 'domain', 'artificial', 'intelligence', 'focus', 'interaction', 'computer', 'human', 'language', 'involves', 'breaking', 'text', 'smaller', 'component', 'word', 'sentence', 'tokenization', 'additionally', 'process', 'like', 'stemming', 'lemmatization', 'help', 'reduce', 'word', 'base', 'form', 'ensuring', 'consistency', 'analysis', 'application', 'nlp', 'include', 'chatbots', 'sentiment', 'analysis', 'language', 'translation', 'ability', 'process', 'understand', 'natural', 'language', 'open', 'world', 'possibility', 'making', 'technology', 'smarter', 'accessible', 'user']\n",
      "Final Preprocessed Text: natural language processing nlp fascinating domain artificial intelligence focus interaction computer human language involves breaking text smaller component word sentence tokenization additionally process like stemming lemmatization help reduce word base form ensuring consistency analysis application nlp include chatbots sentiment analysis language translation ability process understand natural language open world possibility making technology smarter accessible user\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS, preprocess_string, remove_stopwords\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data for lemmatization\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load sample text from a file\n",
    "file_path = \"sample_text.txt\"  # Replace with your text file path\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Step 1: Tokenization using Gensim\n",
    "tokens = simple_preprocess(text)\n",
    "print(\"Tokenized Text:\", tokens)\n",
    "\n",
    "# Step 2: Remove Stopwords using Gensim\n",
    "filtered_tokens = [word for word in tokens if word not in STOPWORDS]\n",
    "print(\"Text after Removing Stopwords:\", filtered_tokens)\n",
    "\n",
    "# Step 3: Apply Stemming using Gensim's PorterStemmer\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(\"Text after Stemming:\", stemmed_tokens)\n",
    "\n",
    "# Step 4: Apply Lemmatization using NLTK's WordNetLemmatizer\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"Text after Lemmatization:\", lemmatized_tokens)\n",
    "\n",
    "# Step 5: Combine back to a single preprocessed text (optional)\n",
    "preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "print(\"Final Preprocessed Text:\", preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bee25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
